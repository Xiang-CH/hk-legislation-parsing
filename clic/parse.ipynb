{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import load_workbook\n",
    "from markdownify import markdownify\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_URL = os.getenv(\"CLIC_SHAREPOINT_URL\")\n",
    "FILE_SAVE_PATH = \"data/CLIC-Content.xlsx\"\n",
    "LANGUAGE_CODE = \"EN\"\n",
    "# LANGUAGE_CODE = \"ZH\"\n",
    "\n",
    "COLS = {\n",
    "    \"EN\": [\"nid\", \"Result\", \"Completed\", \"title\", \"full_path\", \"topic\", \"content\"],\n",
    "    \"ZH\": [\"nid\", \"Result\", \"Completed\", \"title\", \"path\", \"topic\", \"new content\"],\n",
    "}\n",
    "COL_NAMES = [\"nid\", \"type\", \"is_complete\", \"title\", \"path\", \"topic_value\", \"content\"]\n",
    "\n",
    "assert CONTENT_URL, \"SHAREPOINT_URL must be set in .env file\"\n",
    "os.makedirs(os.path.dirname(FILE_SAVE_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the content from SharePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = CONTENT_URL + \"?download=1\"\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n",
    "block_size = 1024\n",
    "with open(FILE_SAVE_PATH, 'wb') as f:\n",
    "    counter = 0\n",
    "    for data in response.iter_content(block_size):\n",
    "        f.write(data)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for removed rows\n",
    "- Indicated by strikethrough formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows to remove: {130, 1672, 909, 1040, 2449, 914, 915, 1567, 1185, 2298, 171, 2607, 48, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 1080, 2615, 2616, 2617, 2618, 2619, 838, 455, 458, 603, 1376, 1377, 227, 228, 2275, 614, 870, 872, 745, 1388, 1389, 878, 1390, 1392, 1268, 1397, 1146, 125, 126}\n"
     ]
    }
   ],
   "source": [
    "ws = load_workbook(FILE_SAVE_PATH)[LANGUAGE_CODE]\n",
    "rows_to_remove = set()\n",
    "# Check each cell for strikethrough formatting\n",
    "for row_idx, row in enumerate(ws.iter_rows(min_row=2)):  # Skip header row\n",
    "    for cell in row:\n",
    "        if cell.font and cell.font.strike:\n",
    "            rows_to_remove.add(row_idx)\n",
    "            break\n",
    "print(f\"Rows to remove: {rows_to_remove}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataframe and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>type</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>title</th>\n",
       "      <th>path</th>\n",
       "      <th>topic_value</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>is_noisy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Criminal liability and types of penalties</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/criminal_li...</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;I. Criminal liability and types of penalti...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Index</td>\n",
       "      <td>False</td>\n",
       "      <td>Criminal records and the Rehabilitation of Off...</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/Criminal-Re...</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;II. Criminal records and the Rehabilitatio...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Police powers</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/police_powers</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;III. Police powers&lt;/h2&gt; &lt;p&gt;As an ordinary ...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nid   type  is_complete                                              title  \\\n",
       "0    8    NaN         True          Criminal liability and types of penalties   \n",
       "1    9  Index        False  Criminal records and the Rehabilitation of Off...   \n",
       "2   10    NaN         True                                      Police powers   \n",
       "\n",
       "                                                path  \\\n",
       "0  /topics/PoliceAndCriminalProcedure/criminal_li...   \n",
       "1  /topics/PoliceAndCriminalProcedure/Criminal-Re...   \n",
       "2   /topics/PoliceAndCriminalProcedure/police_powers   \n",
       "\n",
       "                   topic_value  \\\n",
       "0  Police & Criminal Procedure   \n",
       "1  Police & Criminal Procedure   \n",
       "2  Police & Criminal Procedure   \n",
       "\n",
       "                                             content  \\\n",
       "0  <h2>I. Criminal liability and types of penalti...   \n",
       "1  <h2>II. Criminal records and the Rehabilitatio...   \n",
       "2  <h2>III. Police powers</h2> <p>As an ordinary ...   \n",
       "\n",
       "                                                 url  is_noisy  \n",
       "0  https://clic.org.hk/en/topics/PoliceAndCrimina...     False  \n",
       "1  https://clic.org.hk/en/topics/PoliceAndCrimina...      True  \n",
       "2  https://clic.org.hk/en/topics/PoliceAndCrimina...     False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(FILE_SAVE_PATH, sheet_name=LANGUAGE_CODE, usecols=COLS[LANGUAGE_CODE])\n",
    "df.columns = COL_NAMES\n",
    "df.drop(index=rows_to_remove, inplace=True)\n",
    "df.dropna(subset=[\"title\", \"content\", \"topic_value\"], inplace=True) \n",
    "df.drop(index=df[~df[\"path\"].str.contains(\"topics/\")].index, inplace=True)              # filter out announcement pages\n",
    "\n",
    "df['url'] = df['path']\n",
    "df['path'] = df['path'].apply(lambda x: '/topics/' + x.split('/topics/')[1] if '/topics/' in x else x)\n",
    "\n",
    "# df.drop(index=df[df[\"type\"] == \"Index\"].index, inplace=True)                              # filter out index pages\n",
    "df[\"is_noisy\"] = df[\"type\"] == \"Index\"  # Mark noisy pages\n",
    "\n",
    "df.drop(index=df[df[\"type\"] == \"Delete\"].index, inplace=True)                               # filter out deleted pages\n",
    "df['nid'] = df['nid'].astype(int)                                                     # Convert 'nid' to int\n",
    "df['is_complete'] = df['is_complete'].fillna(0).astype(bool)                    # Convert 'is_complete' to boolean (1.0 -> True, NaN/0.0 -> False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2541 entries, 0 to 2637\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   nid          2541 non-null   int64 \n",
      " 1   type         312 non-null    object\n",
      " 2   is_complete  2541 non-null   bool  \n",
      " 3   title        2541 non-null   object\n",
      " 4   path         2541 non-null   object\n",
      " 5   topic_value  2541 non-null   object\n",
      " 6   content      2541 non-null   object\n",
      " 7   url          2541 non-null   object\n",
      " 8   is_noisy     2541 non-null   bool  \n",
      "dtypes: bool(2), int64(1), object(6)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract CLIC pages' topics keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nid</th>\n",
       "      <th>type</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>title</th>\n",
       "      <th>path</th>\n",
       "      <th>topic_value</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>is_noisy</th>\n",
       "      <th>topic_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Criminal liability and types of penalties</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/criminal_li...</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;I. Criminal liability and types of penalti...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>False</td>\n",
       "      <td>PoliceAndCriminalProcedure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Index</td>\n",
       "      <td>False</td>\n",
       "      <td>Criminal records and the Rehabilitation of Off...</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/Criminal-Re...</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;II. Criminal records and the Rehabilitatio...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>True</td>\n",
       "      <td>PoliceAndCriminalProcedure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Police powers</td>\n",
       "      <td>/topics/PoliceAndCriminalProcedure/police_powers</td>\n",
       "      <td>Police &amp; Criminal Procedure</td>\n",
       "      <td>&lt;h2&gt;III. Police powers&lt;/h2&gt; &lt;p&gt;As an ordinary ...</td>\n",
       "      <td>https://clic.org.hk/en/topics/PoliceAndCrimina...</td>\n",
       "      <td>False</td>\n",
       "      <td>PoliceAndCriminalProcedure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nid   type  is_complete                                              title  \\\n",
       "0    8    NaN         True          Criminal liability and types of penalties   \n",
       "1    9  Index        False  Criminal records and the Rehabilitation of Off...   \n",
       "2   10    NaN         True                                      Police powers   \n",
       "\n",
       "                                                path  \\\n",
       "0  /topics/PoliceAndCriminalProcedure/criminal_li...   \n",
       "1  /topics/PoliceAndCriminalProcedure/Criminal-Re...   \n",
       "2   /topics/PoliceAndCriminalProcedure/police_powers   \n",
       "\n",
       "                   topic_value  \\\n",
       "0  Police & Criminal Procedure   \n",
       "1  Police & Criminal Procedure   \n",
       "2  Police & Criminal Procedure   \n",
       "\n",
       "                                             content  \\\n",
       "0  <h2>I. Criminal liability and types of penalti...   \n",
       "1  <h2>II. Criminal records and the Rehabilitatio...   \n",
       "2  <h2>III. Police powers</h2> <p>As an ordinary ...   \n",
       "\n",
       "                                                 url  is_noisy  \\\n",
       "0  https://clic.org.hk/en/topics/PoliceAndCrimina...     False   \n",
       "1  https://clic.org.hk/en/topics/PoliceAndCrimina...      True   \n",
       "2  https://clic.org.hk/en/topics/PoliceAndCrimina...     False   \n",
       "\n",
       "                    topic_key  \n",
       "0  PoliceAndCriminalProcedure  \n",
       "1  PoliceAndCriminalProcedure  \n",
       "2  PoliceAndCriminalProcedure  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTopicFromPath(path):\n",
    "    if isinstance(path, str) and 'topics/' in path:\n",
    "        x = path.split('topics/')[1]\n",
    "        return x.split('/')[0] if '/' in x else x\n",
    "    return None\n",
    "\n",
    "df['topic_key'] = df['path'].apply(getTopicFromPath)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics in data: 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['PoliceAndCriminalProcedure', 'hkLegalSystem', 'ADR', 'civilCase',\n",
       "       'legalAid', 'personalInjuries',\n",
       "       'bankruptcy_IndividualVoluntaryArrangement_Companies_Winding_up',\n",
       "       'enduring_Powers_of_Attorney', 'DIY_Residential_Tenancy_Agreement',\n",
       "       'Maintenance_and_safety_of_property', 'landlord_tenant',\n",
       "       'Redevelopment_and_Acquisition_of_Property',\n",
       "       'saleAndPurchaseOfProperty', 'probate', 'taxation', 'insurance',\n",
       "       'Medical_treatment_consent_and_withdrawal', 'medicalNegligence',\n",
       "       'sexual_offences', 'traffic_law', 'immigration', 'Competition_Law',\n",
       "       'businessAndCommerce', 'employmentDisputes',\n",
       "       'intellectualProperty', 'FreedomOfAssemblyProcessionDemonstration',\n",
       "       'familyMatrimonialAndCohabitation', 'personalDataPrivacy',\n",
       "       'protectionForInvestorsAndStructuredProducts',\n",
       "       'consumer_complaints', 'antiDiscrimination', 'defamation',\n",
       "       'offences_related_to_dangerous_drugs', 'judicial_review',\n",
       "       'consumerCredit', 'OffencesAgainstThePerson', 'Evidence'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = df['topic_key'].unique()\n",
    "print(f\"Number of topics in data: {len(topics)}\")\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove list index in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = [')', '.', '. ']\n",
    "\n",
    "def cleanTitle(title: str) -> str:    \n",
    "    separator = None\n",
    "    for sep in separators:\n",
    "        if sep in title[:5]:\n",
    "            separator = sep\n",
    "            break\n",
    "        \n",
    "    if separator is None:\n",
    "        return title.strip()\n",
    "    \n",
    "    return title.split(separator, 1)[-1].strip()\n",
    "\n",
    "df['title'] = df['title'].apply(cleanTitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if title is question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 1414, out of 2541 total rows.\n"
     ]
    }
   ],
   "source": [
    "df['is_question'] = df['title'].apply(lambda x: x.endswith('?'))\n",
    "\n",
    "is_question_count = len(df[df['is_question'] == True])\n",
    "print(f\"Number of questions: {is_question_count}, out of {len(df)} total rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parseCamel(text):\n",
    "    if len(text) < 5:\n",
    "        return text\n",
    "    # Split on uppercase letters, but not at the start of the string\n",
    "    x = re.split(r'(?<!^)(?=[A-Z])', text)\n",
    "    if len(x) > 1:\n",
    "        if x[0].isnumeric():\n",
    "            x = x[1:]  # If the first part is numeric, skip it\n",
    "        else:\n",
    "            x[0] = x[0][0].upper() + x[0][1:]\n",
    "    return \" \".join(x)\n",
    "\n",
    "def parseSnake(text):\n",
    "    # x = re.sub('(_)([a-zA-Z0-9])', lambda x: ' ' + x.group(2).upper(), text)\n",
    "    x = text.split('_')\n",
    "    if len(x) > 1 and x[0].isnumeric():\n",
    "        x = x[1:]  # If the first part is numeric, skip it\n",
    "    return \" \".join(x)\n",
    "\n",
    "\n",
    "# Example path: https://clic.org.hk/zh/topics/FreedomOfAssemblyProcessionDemonstration/RelatedOffences/Public_Order_Offences/Disorder_in_public_places\n",
    "def getContext(path: str, topic: str) -> str:\n",
    "    ctx = path.split('topics/')[1].split('/')[1:-1]\n",
    "    ctx = [topic] + [parseSnake(x) if '_' in x else parseCamel(x) for x in ctx]\n",
    "    return ' > '.join(ctx)\n",
    "\n",
    "# getContext('https://clic.org.hk/en/topics/ADR/Mediation/relevantPracticeDirections/pd18.1&18.2', 'Freedom Of Assembly Procession Demonstration')\n",
    "df['context'] = df.apply(lambda x: getContext(x['path'], x['topic_value']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_newlines(text):\n",
    "    # Replace 2 or more consecutive newlines with exactly two newlines\n",
    "    return re.sub(r'(\\s*\\n\\s*){2,}', '\\n\\n', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove header line and convert to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nid type  is_complete                                      title  \\\n",
      "0    8  NaN         True  Criminal liability and types of penalties   \n",
      "\n",
      "                                                path  \\\n",
      "0  /topics/PoliceAndCriminalProcedure/criminal_li...   \n",
      "\n",
      "                   topic_value  \\\n",
      "0  Police & Criminal Procedure   \n",
      "\n",
      "                                             content  \\\n",
      "0  <h2>I. Criminal liability and types of penalti...   \n",
      "\n",
      "                                                 url  is_noisy  \\\n",
      "0  https://clic.org.hk/en/topics/PoliceAndCrimina...     False   \n",
      "\n",
      "                    topic_key  is_question                      context  \\\n",
      "0  PoliceAndCriminalProcedure        False  Police & Criminal Procedure   \n",
      "\n",
      "                                      parsed_content  \n",
      "0  Criminal liability is generally made up of two...  \n"
     ]
    }
   ],
   "source": [
    "content_no_header = df['content'].apply(lambda x: x.split(\"</h2>\", maxsplit=1)[1].strip() if len(x.split(\"</h2>\")) > 1 else x)\n",
    "df['parsed_content'] = content_no_header.apply(lambda x: normalize_newlines(markdownify(x).strip()))\n",
    "print(df.head(1))\n",
    "del content_no_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract CLIC, legislation and case references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = f\"https://clic.org.hk/{LANGUAGE_CODE.lower()}/topics/\"\n",
    "def find_new_path(path: str, retries=0) -> str:\n",
    "    '''\n",
    "    For some pages the path has changed, but some hyperlinks still point to the old path.\n",
    "    This function finds the new URL based on the old path.\n",
    "    '''\n",
    "    if not isinstance(path, str):\n",
    "        return None\n",
    "    url = BASE_URL + path\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5, allow_redirects=True)\n",
    "        if response.status_code in [200, 301]:\n",
    "            # print(f\"Found new path for {path}: {response.url}\")\n",
    "            return response.url.split('/topics/')[1].strip() if '/topics/' in response.url else None\n",
    "        else:\n",
    "            raise requests.RequestException(f\"Failed to fetch {url}: {response.status_code}\")\n",
    "    except requests.RequestException:\n",
    "        if retries < 3:\n",
    "            return find_new_path(path, retries + 1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cases_ref'] = None\n",
    "df['legislation_ref'] = None\n",
    "df['clic_ref'] = None\n",
    "\n",
    "for i, col in df.iterrows():\n",
    "    soup = BeautifulSoup(col[\"content\"], 'html.parser')\n",
    "    cap = []\n",
    "    cases = []\n",
    "    clic = []\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    for link in links:\n",
    "\n",
    "        if link.has_attr('href') and \"hklii\" in link['href']:\n",
    "            # hklii links can be cases or legislation\n",
    "            url = link['href'].split('?')[0] if \"?\" in link['href'] else link['href']\n",
    "            url = url[:-5] if link['href'].endswith('.html') else url\n",
    "            \n",
    "            if 'cases' in link['href']:\n",
    "                # Parse Cases (https://www.hklii.hk/en/cases/hkca/2020/124 or https://www.hklii.org/cgi-bin/sinodisp/eng/hk/cases/hkcfi/2018/2243.html)\n",
    "                metadata = url.split('/cases')[1].strip().split('/')\n",
    "                if len(metadata) >= 3:\n",
    "                    cases.append({\n",
    "                        'court': metadata[1],\n",
    "                        'year': metadata[2],\n",
    "                        'no': metadata[3]\n",
    "                    })\n",
    "            else:\n",
    "                # Parse Legislation (http://www.hklii.hk/hk/legis/en/ord/344/ or https://www.hklii.org/eng/hk/legis/reg/382A/s12.html or http://www.hklii.hk/eng/hk/legis/instrument/101/)\n",
    "                leg_type = 'ord' if '/ord/' in url else 'reg' if '/reg/' in url else 'instrument' if '/instrument/' in url else None\n",
    "                if leg_type is None: continue\n",
    "\n",
    "                metadata = url.split(f'/{leg_type}/')[1].strip().split('/')\n",
    "                if len(metadata) >= 1:\n",
    "                    cap.append({\n",
    "                        'type': leg_type,\n",
    "                        'no': metadata[0] if leg_type != 'instrument' else f\"A{metadata[0]}\" if metadata[0].isdigit() else metadata[0],\n",
    "                        'section': metadata[1] if len(metadata) > 1 else \"\"\n",
    "                    })\n",
    "        \n",
    "        elif link.has_attr('href') and \"/topics/\" in link['href']:\n",
    "            # References to other pages on the CLIC site\n",
    "            page_path = link['href']\n",
    "            if \"#\" in page_path:\n",
    "                # Remove fragment identifiers (e.g., #section1)\n",
    "                page_path = page_path.split('#')[0]\n",
    "            page_path = page_path.split('/topics/')[1].strip()\n",
    "            if page_path.endswith('/'):\n",
    "                page_path = page_path[:-1]\n",
    "\n",
    "            # Find the corresponding nid in the DataFrame\n",
    "            page_nids = df[df['path'].str.endswith(page_path)]['nid'].values\n",
    "            if len(page_nids) == 0:\n",
    "                # If no nid found, try to find the new URL\n",
    "                new_url = find_new_path(page_path)\n",
    "                if new_url:\n",
    "                    page_nids = df[df['path'].str.endswith(new_url)]['nid'].values\n",
    "\n",
    "            clic.append({\n",
    "                'nid': page_nids[0] if len(page_nids) > 0 else None,\n",
    "                'path': '/topics/' + page_path.strip(),\n",
    "            })\n",
    "            \n",
    "    df.at[i, 'cases_ref'] = cases\n",
    "    df.at[i, 'legislation_ref'] = cap\n",
    "    df.at[i, 'clic_ref'] = clic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tokens in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "df['n_tokens'] = df['parsed_content'].apply(lambda x: len(enc.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of long texts (more than 1024 tokens): 141\n",
      "Number of long texts (more than 512 tokens): 504\n",
      "Number of long texts (more than 256 tokens): 1125\n",
      "Number of short texts (less than 12 tokens): 208\n"
     ]
    }
   ],
   "source": [
    "over_1024_texts = df[df['n_tokens'] > 1024]\n",
    "print(f\"Number of long texts (more than 1024 tokens): {len(over_1024_texts)}\")\n",
    "\n",
    "over_512_texts = df[df['n_tokens'] > 512]\n",
    "print(f\"Number of long texts (more than 512 tokens): {len(over_512_texts)}\")\n",
    "\n",
    "over_256_texts = df[df['n_tokens'] > 256]\n",
    "print(f\"Number of long texts (more than 256 tokens): {len(over_256_texts)}\")\n",
    "\n",
    "under_12_texts = df[df['n_tokens'] < 12]\n",
    "print(f\"Number of short texts (less than 12 tokens): {len(under_12_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_noisy'] = df['n_tokens'] < 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['n_tokens'] > 512].to_excel(\"data/CLIC_content_512_tokens.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(\"data/CLIC_content_cleaned.xlsx\", index=False)\n",
    "df.to_json(\"data/CLIC_content_cleaned.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
